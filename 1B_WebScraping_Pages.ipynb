{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Web Scraping Stack Overflow - Part II - Multiple pages\n",
    "\n",
    "### Base code modified and expanded from\n",
    "### https://medium.com/better-programming/how-to-scrape-multiple-pages-of-a-website-using-a-python-web-scraper-4e2c641cff8"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from bs4 import BeautifulSoup as bs\n",
    "import requests\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "#user_span_single = user_spans[0]\n",
    "\n",
    "def user_find(user_span_single):\n",
    "    \n",
    "    trial = user_span_single.select('a')\n",
    "    \n",
    "    if len(trial) >= 1:\n",
    "    \n",
    "        intermediate = trial[0].text\n",
    "        \n",
    "        if '\\r\\n' in intermediate:\n",
    "        \n",
    "            return None\n",
    "        \n",
    "        return intermediate\n",
    "    \n",
    "    if 'anon' in user_span_single.text:\n",
    "    \n",
    "        return 'anonymous'\n",
    "    \n",
    "    else:\n",
    "        check = user_span_single.get_text(strip=True)\n",
    "        \n",
    "        if not check:\n",
    "        \n",
    "            return 'no_user_info'\n",
    "    \n",
    "        return check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#time_spans = body.select(\"span.relativetime\")\n",
    "#time_stamp = [i[\"title\"] for i in time_spans]\n",
    "\n",
    "def time_find(users, time_stamp):\n",
    " \n",
    "    polished_times = []\n",
    "    times_iter = iter(time_stamp)\n",
    "\n",
    "    for user_id in users:\n",
    "        if user_id == 'community wiki' or user_id == 'anonymous':\n",
    "            polished_times.append('None') \n",
    "        \n",
    "        else:\n",
    "            polished_times.append(next(times_iter))\n",
    "            \n",
    "    \n",
    "    return polished_times"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3090\n",
      "3091\n"
     ]
    }
   ],
   "source": [
    "for i in range(3090,3092):\n",
    "\n",
    "    questions = []\n",
    "    summaries = []\n",
    "    tags = []\n",
    "    times = []\n",
    "    users = []\n",
    "    no_of_votes = []\n",
    "    no_of_answers = []\n",
    "    failed = []\n",
    "    \n",
    "    pages = np.arange((i * 100 + 1) - 100, i * 100 + 1, 1)\n",
    "\n",
    "    \n",
    "    try:\n",
    "    \n",
    "        for page in pages:\n",
    "\n",
    "            #def get_top_questions(page):\n",
    "            # WARNING: Only enter one of these 3 values [15, 30, 50].\n",
    "            # Since, stackoverflow, doesn't display any other size questions list\n",
    "            #url = url + \"?sort=votes&pagesize={}\".format(question_count)\n",
    "\n",
    "            # Using requests module for downloading webpage content\n",
    "            page = requests.get(\"https://stackoverflow.com/questions?tab=active&page=\" + str(page))\n",
    "\n",
    "            # Parsing html data using BeautifulSoup\n",
    "            soup = bs(page.content, 'html.parser')\n",
    "            body = soup.find('body')\n",
    "\n",
    "            # Extracting Top Questions\n",
    "            question_links = body.select(\"h3 a.question-hyperlink\")\n",
    "            #error_checking(question_links, question_count)                     # Error Checking\n",
    "            questions.extend([i.text for i in question_links])                      # questions list\n",
    "\n",
    "            # Extracting Summary\n",
    "            summary_divs = body.select(\"div.excerpt\")\n",
    "            #error_checking(summary_divs, question_count)                       # Error Checking\n",
    "            summaries.extend([i.text.strip() for i in summary_divs])                 # summaries list\n",
    "\n",
    "            # Extracting Tags\n",
    "            tags_divs = body.select(\"div.summary > div:nth-of-type(2)\")\n",
    "\n",
    "            #error_checking(tags_divs, question_count)                          # Error Checking\n",
    "            a_tags_list = [i.select('a') for i in tags_divs]                   # tag links\n",
    "\n",
    "            tagged_tags = []\n",
    "\n",
    "            for a_group in a_tags_list:\n",
    "                    tagged_tags.append([a.text for a in a_group])                         # tags list\n",
    "\n",
    "            tags.extend(tagged_tags)\n",
    "\n",
    "            # Extracting User Info\n",
    "            user_spans = body.select(\"div.user-details\")\n",
    "            user_found = [user_find(user_span_single) for user_span_single in user_spans]\n",
    "            users_list = [x for x in user_found if x]\n",
    "            users.extend([x for x in user_found if x])\n",
    "            #print(len(users))\n",
    "\n",
    "            # Extracting Question Time Stamps\n",
    "            time_spans = body.select(\"span.relativetime\")\n",
    "            time_stamp = [i[\"title\"] for i in time_spans]\n",
    "            times.extend(time_find(users_list, time_stamp))\n",
    "\n",
    "            #print(len(time_spans))                                             # time list\n",
    "\n",
    "            # Extracting Number of votes\n",
    "            vote_spans = body.select(\"span.vote-count-post strong\")\n",
    "            #error_checking(vote_spans, question_count)                         # Error Checking\n",
    "            no_of_votes.extend([int(i.text) for i in vote_spans])                    # votes list\n",
    "\n",
    "            # Extracting Number of answers\n",
    "            answer_divs = body.select(\"div.status strong\")\n",
    "            #error_checking(answer_divs, question_count)                        # Error Checking\n",
    "            no_of_answers.extend([int(i.text) for i in answer_divs])                 # answers list\n",
    "\n",
    "        # Putting all of them together\n",
    "        test_df = pd.DataFrame({'question': questions, \n",
    "                                'summary': summaries, \n",
    "                                'tags': tags,\n",
    "                                'time_stamp': times,\n",
    "                                'user_id': users,\n",
    "                                'no_of_votes': no_of_votes,\n",
    "                                'no_of_answers': no_of_answers})\n",
    "\n",
    "        test_df.to_csv('scrape/test_scrape_{}.csv'.format(str(i).zfill(4)))\n",
    "\n",
    "        print(i) \n",
    "        \n",
    "    except:\n",
    "        failed.append(i)\n",
    "\n",
    "        failed_df = pd.DataFrame({'location': failed})\n",
    "        failed_df.to_csv('failed_df.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fail Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(times)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(users)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(no_of_answers)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
